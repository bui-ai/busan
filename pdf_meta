import os
import re
import fitz  # PyMuPDF
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import tkinter as tk
from tkinter import filedialog, messagebox, ttk
from datetime import datetime
from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import sys
import io

class RedirectText(io.StringIO):
    def __init__(self, text_widget):
        super().__init__()
        self.text_widget = text_widget
        self.text_widget.config(state=tk.NORMAL)

    def write(self, string):
        self.text_widget.insert(tk.END, string)
        self.text_widget.see(tk.END)
        self.text_widget.update_idletasks()
        
    def flush(self):
        pass

def extract_metadata_from_filename(filename):
    match = re.match(r"^(\d{6,8})[\- _]?(.*)\.pdf$", filename)  # 6~8ìë¦¬ ìˆ«ì ì¶”ì¶œ + êµ¬ë¶„ì ì²˜ë¦¬
    if not match:
        return None, None

    raw_date, title = match.groups()
    title = title.strip("-_ ")  # ì œëª©ì—ì„œ êµ¬ë¶„ì ì œê±°

    if len(raw_date) == 6:  # YYMMDD í˜•ì‹ (ì˜ˆ: 230501)
        year_base = int(raw_date[:2])

        # 80 ì´ìƒì´ë©´ 1900ë…„ëŒ€, ê·¸ ì´í•˜ë©´ 2000ë…„ëŒ€
        if year_base >= 80:
            year = f"19{year_base}"
        else:
            year = f"20{year_base}"

        month = raw_date[2:4]
        day = raw_date[4:]
    elif len(raw_date) == 8:
        year = raw_date[:4]
        month = raw_date[4:6]
        day = raw_date[6:]
    else:
        return None, title
    
    formatted_date = f"{year}-{month}-{day}"
    return formatted_date, title

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = "\n".join([page.get_text("text") for page in doc])
    return text

def cluster_and_select_key_sentences(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    sentences = text_splitter.split_text(text)

    # ë¬¸ì¥ì´ 5ê°œ ì´í•˜ë¼ë©´ í´ëŸ¬ìŠ¤í„°ë§ ì—†ì´ ì „ì²´ ë¬¸ì¥ì„ ë°˜í™˜
    if len(sentences) <= 5:
        return "\n".join(sentences)

    # ë¬¸ì¥ ìˆ˜ì˜ 30% ë˜ëŠ” ìµœì†Œ 3ê°œì˜ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
    num_clusters = max(3, min(5, len(sentences) // 3))

    embedding_model = HuggingFaceEmbeddings(model_name="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    sentence_vectors = np.array([embedding_model.embed_query(sentence) for sentence in sentences])

    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
    kmeans.fit(sentence_vectors)
    cluster_centers = kmeans.cluster_centers_

    selected_sentences = []
    for center in cluster_centers:
        distances = np.linalg.norm(sentence_vectors - center, axis=1)
        closest_sentence_idx = np.argmin(distances)
        selected_sentences.append(sentences[closest_sentence_idx])

    return "\n".join(selected_sentences)


def generate_summary_and_keywords(text):
    try:
        llm = ChatOllama(model="EXAONE-3.5-7.8B-Instruct", temperature=0.3)

        key_sentences = cluster_and_select_key_sentences(text)
        if len(key_sentences) < 50:
            key_sentences = text[:1000]

        prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ì— ì •í™•íˆ ë§ì¶° ì‘ë‹µí•˜ì„¸ìš”:

        ìš”ì•½: (200ì ì´ë‚´ë¡œ, í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ì„œìˆ )
        í‚¤ì›Œë“œ: (10ê°œ ì´ë‚´, ë‹¨ì–´ë§Œ ì œê³µ, ì‰¼í‘œë¡œ êµ¬ë¶„)        

        ë¬¸ì„œ ë‚´ìš©:
        {key_sentences}
        """

        response = llm.invoke([HumanMessage(content=prompt)])
        output_text = response.content.strip()
        print("ğŸ“¥ LLM ì‘ë‹µ:", output_text)

        # ìš”ì•½ ì •ê·œì‹ 1ì°¨ ì‹œë„
        summary_match = re.search(r"(?:ìš”ì•½|1[.)ï¼š:])\s*[-:]?\s*(.+?)(?:\n|í‚¤ì›Œë“œ|2[.)ï¼š:])", output_text, re.DOTALL)
        keywords_match = re.search(r"(?:í‚¤ì›Œë“œ|2[.)ï¼š:])\s*[-:]?\s*(.+)", output_text)

        summary = summary_match.group(1).strip() if summary_match else ""
        keywords = keywords_match.group(1).strip() if keywords_match else ""

        # Fallback ìš”ì•½
        if not summary:
            summary_lines = [line for line in output_text.splitlines() if "ìš”ì•½" in line or "1." in line]
            if summary_lines:
                summary = summary_lines[0].split(":", 1)[-1].strip()
            else:
                summary = output_text.split("\n")[0][:200].strip()

        # Fallback í‚¤ì›Œë“œ
        if not keywords:
            keyword_lines = [line for line in output_text.splitlines() if "í‚¤ì›Œë“œ" in line or "2." in line]
            if keyword_lines:
                keywords = keyword_lines[0].split(":", 1)[-1].strip()
            else:
                found_words = re.findall(r"\b[ê°€-í£]{2,10}\b", output_text)
                keywords = ", ".join(found_words[:10])

        if " " in keywords and "," not in keywords:
            keywords = ", ".join(keywords.split())

        return summary[:200], keywords

    except Exception as e:
        return f"LLM ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "í‚¤ì›Œë“œ ì—†ìŒ"

def update_pdf_metadata(pdf_path, title, subject, keywords, creation_date, output_folder):
    doc = fitz.open(pdf_path)
    
    if doc.is_encrypted:
        try:
            doc.authenticate("")  # ì•”í˜¸ ì—†ëŠ” ê²½ìš° í•´ì œ ì‹œë„
        except Exception:
            print(f"âš ï¸ ì•”í˜¸í™”ëœ PDF: {pdf_path}, ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ë¶ˆê°€")
            return
    
    metadata = doc.metadata
    metadata["title"] = title  # Titleì€ ë¬¸ì„œ ì œëª©
    metadata["subject"] = subject  # SubjectëŠ” ìš”ì•½ ë‚´ìš©
    metadata["keywords"] = keywords
    metadata["creationDate"] = datetime.strptime(creation_date, "%Y-%m-%d").isoformat()
    
    output_path = os.path.join(output_folder, os.path.basename(pdf_path))
    temp_path = output_path + "_temp.pdf"
    
    new_doc = fitz.open()
    for page in doc:
        new_doc.insert_pdf(doc, from_page=page.number, to_page=page.number)
    
    new_doc.set_metadata(metadata)
    new_doc.save(temp_path, garbage=4, deflate=True, incremental=False)
    new_doc.close()
    doc.close()
    os.replace(temp_path, output_path)

def process_pdf(pdf_path, output_folder):
    """ê°œë³„ PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ì²˜ë¦¬ í›„ ë°”ë¡œ CSV íŒŒì¼ì— ê²°ê³¼ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤."""
    filename = os.path.basename(pdf_path)
    creation_date, title = extract_metadata_from_filename(filename)
    if not creation_date:
        print(f"âš ï¸ íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {filename}")
        return
    
    text = extract_text_from_pdf(pdf_path)
    summary, keywords = generate_summary_and_keywords(text)
    
    update_pdf_metadata(pdf_path, title, summary, keywords, creation_date, output_folder)
    print(f"âœ… {filename} ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    
    # íŒŒì¼ í•˜ë‚˜ ì²˜ë¦¬ í›„ ë°”ë¡œ CSVì— ê²°ê³¼ ì¶”ê°€
    output_csv = os.path.join(output_folder, "pdf_metadata.csv")
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (í•„ìš”ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
    text_preview = text[:1000].replace("\n", " ").strip()
    
    metadata_item = {
        "Filename": filename,
        "Title": title,
        "Subject": summary,
        "Keywords": keywords,
        "Creation Date": creation_date,
        "Text Preview": text_preview,
        "Full Text": text  # ì „ì²´ í…ìŠ¤íŠ¸ë„ ì €ì¥
    }
    
    # CSV íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•˜ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    try:
        if os.path.exists(output_csv) and os.path.getsize(output_csv) > 0:
            df = pd.read_csv(output_csv, sep=",", dtype=str)
            # 'Filename' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if "Filename" not in df.columns:
                df = pd.DataFrame(columns=["Filename", "Title", "Subject", "Keywords", "Creation Date", "Text Preview", "Full Text"])
        else:
            df = pd.DataFrame(columns=["Filename", "Title", "Subject", "Keywords", "Creation Date", "Text Preview", "Full Text"])
    except (pd.errors.EmptyDataError, pd.errors.ParserError):
        df = pd.DataFrame(columns=["Filename", "Title", "Subject", "Keywords", "Creation Date", "Text Preview", "Full Text"])
    
    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ ê°™ì€ íŒŒì¼ëª…ì´ ìˆìœ¼ë©´ ì œê±°
    df = df[df["Filename"] != filename]
    
    # ìƒˆ ë°ì´í„° ì¶”ê°€
    df = pd.concat([df, pd.DataFrame([metadata_item])], ignore_index=True)
    
    # CSV íŒŒì¼ ì €ì¥ - íŒŒì¼ í¬ê¸° ê´€ë¦¬ë¥¼ ìœ„í•´ Text Previewë§Œ CSVì— ì €ì¥í•˜ê³  Full TextëŠ” ë³„ë„ íŒŒì¼ì— ì €ì¥í•˜ëŠ” ì˜µì…˜
    csv_df = df.copy()
    
    if len(text) > 10000:  # í…ìŠ¤íŠ¸ê°€ ë§¤ìš° ê¸´ ê²½ìš° ë³„ë„ ì €ì¥ ì˜µì…˜ (í•„ìš”ì— ë”°ë¼ ì¡°ì •)
        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë³„ë„ì˜ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        text_folder = os.path.join(output_folder, "extracted_texts")
        os.makedirs(text_folder, exist_ok=True)
        text_file_path = os.path.join(text_folder, f"{os.path.splitext(filename)[0]}.txt")
        
        with open(text_file_path, "w", encoding="utf-8") as f:
            f.write(text)
        
        # CSVì—ëŠ” í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°ë§Œ ì €ì¥í•˜ê³  ì „ì²´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
        if "Full Text" in csv_df.columns:
            csv_df.drop(columns=["Full Text"], inplace=True)
        print(f"ê¸´ í…ìŠ¤íŠ¸ëŠ” ë³„ë„ íŒŒì¼ë¡œ ì €ì¥ë¨: {text_file_path}")
    
    csv_df.to_csv(output_csv, index=False, encoding="utf-8-sig", sep=",")
    print(f"ğŸ“„ {filename}ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ CSVì— ì €ì¥ ì™„ë£Œ!")
    
    return metadata_item

def process_pdf_folder(input_folder, output_folder):
    """í´ë” ë‚´ ëª¨ë“  PDF íŒŒì¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    # CSV íŒŒì¼ ê²½ë¡œ
    output_csv = os.path.join(output_folder, "pdf_metadata.csv")
    processed_count = 0
    
    for file in os.listdir(input_folder):
        if file.endswith(".pdf"):
            process_pdf(os.path.join(input_folder, file), output_folder)
            processed_count += 1
    
    print(f"ğŸ“Š ì´ {processed_count}ê°œì˜ PDF íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
    return output_csv

def show_main_window():
    root = tk.Tk()
    root.title("PDF ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ ë„êµ¬")
    root.geometry("700x400")
    
    def select_input_folder():
        folder = filedialog.askdirectory(title="ì…ë ¥ í´ë” ì„ íƒ")
        if folder:
            input_folder_var.set(folder)
    
    def select_output_folder():
        folder = filedialog.askdirectory(title="ì¶œë ¥ í´ë” ì„ íƒ")
        if folder:
            output_folder_var.set(folder)
    
    def process_files():
        input_folder = input_folder_var.get()
        output_folder = output_folder_var.get()
        
        if not input_folder or not output_folder:
            messagebox.showerror("ì˜¤ë¥˜", "ì…ë ¥ ë° ì¶œë ¥ í´ë”ë¥¼ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”.")
            return
        
        log_text.delete(1.0, tk.END)  # ë¡œê·¸ ì´ˆê¸°í™”
        process_pdf_folder(input_folder, output_folder)
    
    input_folder_var = tk.StringVar()
    output_folder_var = tk.StringVar()
    
    frame = tk.Frame(root)
    frame.pack(pady=10)
    
    tk.Label(frame, text="ì…ë ¥ í´ë”:").grid(row=0, column=0, padx=5)
    tk.Entry(frame, textvariable=input_folder_var, width=50).grid(row=0, column=1, padx=5)
    tk.Button(frame, text="ì„ íƒ", command=select_input_folder).grid(row=0, column=2, padx=5)
    
    tk.Label(frame, text="ì¶œë ¥ í´ë”:").grid(row=1, column=0, padx=5)
    tk.Entry(frame, textvariable=output_folder_var, width=50).grid(row=1, column=1, padx=5)
    tk.Button(frame, text="ì„ íƒ", command=select_output_folder).grid(row=1, column=2, padx=5)
    
    # PDF ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼ì„ ìš°ì¸¡ì— ë°°ì¹˜
    process_button = tk.Button(frame, text="PDF ì²˜ë¦¬ ì‹œì‘", command=process_files, 
                              height=2, width=15, bg="#f0f0f0")
    process_button.grid(row=0, column=3, rowspan=2, padx=20, pady=5)
    
    # ì„¤ëª… í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ê°€
    description_frame1 = tk.Frame(root)
    description_frame1.pack(fill=tk.X, padx=10, pady=(5, 0))
    
    description_label1 = tk.Label(description_frame1, text="ğŸ“Œ í”„ë¡œê·¸ë¨ ê¸°ëŠ¥ ì„¤ëª…:", anchor="w", font=("Arial", 9, "bold"))
    description_label1.pack(side=tk.LEFT, anchor="nw")
    
    description_frame2 = tk.Frame(root)
    description_frame2.pack(fill=tk.X, padx=10, pady=(0, 5))
    
    description_label2 = tk.Label(description_frame2, text="ì…ë ¥í´ë” ë‚´ PDF íŒŒì¼(í˜•íƒœ: ë‚ ì§œ(20250316)_ë³´ê³ ì„œ.pdf)ì˜ ë©”íƒ€ë°ì´í„°(ìš”ì•½, í‚¤ì›Œë“œ, ë‚ ì§œ)ë¥¼ ìƒì„±í•˜ì—¬ ì¶œë ¥í´ë”ì— ì €ì¥", anchor="w", font=("Arial", 9))
    description_label2.pack(side=tk.LEFT, anchor="nw")
    
    # ë¡œê·¸ í…ìŠ¤íŠ¸ ìœ„ì ¯ ì„¤ì •
    log_text = tk.Text(root, height=10, wrap=tk.WORD)
    log_text.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
    
    # ì‘ì„±ì ì •ë³´ ì¶”ê°€
    author_label = tk.Label(root, text="Â© 2025 ë„ì‹œí˜ì‹ ê· í˜•ì‹¤ AI í™œì„±í™” ì—°êµ¬íŒ€", fg="gray")
    author_label.pack(side=tk.BOTTOM, pady=5)
    
    # í‘œì¤€ ì¶œë ¥ì„ ë¡œê·¸ í…ìŠ¤íŠ¸ ìœ„ì ¯ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰ì…˜
    sys.stdout = RedirectText(log_text)
    
    root.mainloop()
    
    # í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í‘œì¤€ ì¶œë ¥ ë³µì›
    sys.stdout = sys.__stdout__

if __name__ == "__main__":
    show_main_window()
